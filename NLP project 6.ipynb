{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec1b8a6",
   "metadata": {},
   "source": [
    "### REGEX basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cec415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b4ea617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample text\n",
    "text = \"This is a sample number (555) 555-5555.\"\n",
    "\n",
    "#build upon the spaCy Small Model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "#Create the ruler and add it \n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "#List of Entity and Patterns  \n",
    "patterns = [\n",
    "    {\n",
    "        \"label\": \"PHONE_NUMBER\",\n",
    "        \"pattern\":\n",
    "        [{\"TEXT\":\n",
    "          {\"REGEX\": \"((\\d){3})-(\\d){4}\"}} #this is the sequnce that it looking for\n",
    "                                          #the sequnce is 3 digits followed by - then 4 digits\n",
    "                                          #This pattern applies only to a single token.\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "#add patterns to ruler\n",
    "ruler.add_patterns (patterns)\n",
    "\n",
    "#create the doc\n",
    "doc = nlp(text)\n",
    "\n",
    "#extact entities \n",
    "for ent in doc. ents:\n",
    "    print (ent.text, ent.label_)\n",
    "\n",
    "#the code doesnt output any thing because the patern matching works with REGEX with one single token\n",
    "#you cant use regex with multi tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced2f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55555 PHONE_NUMBER\n"
     ]
    }
   ],
   "source": [
    "#Sample text\n",
    "text = \"This is a sample number (555) 55555.\"\n",
    "\n",
    "#build upon the spaCy Small Model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "#Create the ruler and add it \n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "#List of Entity and Patterns \n",
    "patterns = [\n",
    "    {\n",
    "        \"label\": \"PHONE_NUMBER\",\n",
    "        \"pattern\":\n",
    "        [{\"TEXT\":\n",
    "          {\"REGEX\": \"((\\d){5})\"}} #this is the sequnce that it looking for\n",
    "                                          #the sequnce is 5 digits\n",
    "                                         \n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "#add patterns to ruler\n",
    "ruler.add_patterns (patterns)\n",
    "\n",
    "#create the doc\n",
    "doc = nlp(text)\n",
    "\n",
    "#extact entities \n",
    "for ent in doc. ents:\n",
    "    print (ent.text, ent.label_)\n",
    "\n",
    "#The code give output as the regex is only single token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f408a72",
   "metadata": {},
   "source": [
    "### REGEX Multi-Words Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b554ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7b56caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Paul Newman was an American ator, but Paul Hollywood is a British TV Host. The name Paul is quite common.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a88e8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"Paul [A-Z]\\w+\" \n",
    "# Matches the exact word \"Paul\" \n",
    "# then \tMatches one uppercase letter (e.g., \"M\")\n",
    "# \\w+\tMatches one or more word characters: [a-zA-Z0-9_]\n",
    "# A space separates \"Paul\" and the next name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "378971e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 11), match='Paul Newman'>\n",
      "Paul Newman\n",
      "<re.Match object; span=(38, 52), match='Paul Hollywood'>\n",
      "Paul Hollywood\n"
     ]
    }
   ],
   "source": [
    "#Search in raw text using regex\n",
    "matches = re.finditer(pattern, text)  #Finds all matches of the pattern in the text using re.finditer,\n",
    "                                      #which returns match objects.\n",
    "for match in matches:\n",
    "    print(match)                      #Prints each match object \n",
    "    print(match.group())              #Prints each match TEXT\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d602cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdcf66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load blank spaCy pipeline\n",
    "nlp = spacy.blank(\"en\") #Loads a blank English spaCy pipeline (no tokenizer or components except the default rules).\n",
    "                        #No NER, POS tagging, or lemmatization unless added manually.\n",
    "\n",
    "#Create spaCy doc\n",
    "doc = nlp(text)\n",
    "\n",
    "#Copy the current named entities \n",
    "original_ents = list (doc.ents) #In this case, it's likely an empty list because the blank pipeline has no NER.\n",
    "\n",
    "#Create list to hold new spans (matches from regex)\n",
    "mwt_ents = [] #store new matched spans for custom entity creation (like multi-word tokens).\n",
    "\n",
    "#Run regex again, but now convert character spans to spaCy spans\n",
    "for match in re.finditer(pattern, doc.text):\n",
    "    start, end = match.span() #Gets the character offsets of the match.\n",
    "                              #e.g., if \"Paul Smith\" starts at character 5 and ends at 16 → (5, 16)\n",
    "\n",
    "    span = doc.char_span(start,end) #Converts character offsets into a Span (a slice of tokens from doc)\n",
    "                                    #If the match aligns cleanly with token boundaries, char_span will succeed.\n",
    "                                    #If not, span will be None — always check it.\n",
    "\n",
    "    #print (span) #Displays the actual matched Span, or None if it failed due to misalignment.\n",
    "\n",
    "    if span is not None:\n",
    "        mwt_ents.append((span.start, span.end, span.text))\n",
    "    \n",
    "#Purpose of the Code is to use a regex pattern to find matches in raw text (character positions),\n",
    "#then convert those character spans into spaCy Span objects\n",
    "#and finally extract their start token index, end token index, and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b185026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2, 'Paul Newman'), (8, 10, 'Paul Hollywood')]\n"
     ]
    }
   ],
   "source": [
    "print (mwt_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6340d26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Newman PERSON\n",
      "Paul Hollywood PERSON\n"
     ]
    }
   ],
   "source": [
    "#converting regex-based matches into actual named entities in spaCy's Doc object.\n",
    "\n",
    "#This loop goes through each custom match that was stored in mwt_ents earlier.\n",
    "for ent in mwt_ents: #Each ent in mwt_ents is a tuple: (start_token_index, end_token_index, matched_text)\n",
    "    start, end, name =ent\n",
    "    \n",
    "    per_ent = Span(doc, start, end, label = \"PERSON\")\n",
    "    original_ents.append(per_ent)\n",
    "doc.ents = original_ents\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60f29526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"paul_ner\")\n",
    "def paul_ner(doc):\n",
    "    pattern = pattern = r\"Paul [A-Z]\\w+\" \n",
    "    original_ents = list (doc.ents) \n",
    "    mwt_ents = [] \n",
    "    for match in re.finditer(pattern, doc.text):\n",
    "        start, end = match.span()\n",
    "\n",
    "        span = doc.char_span(start,end)\n",
    "        if span is not None:\n",
    "            mwt_ents.append((span.start, span.end, span.text))\n",
    "\n",
    "    for ent in mwt_ents: \n",
    "        start, end, name =ent\n",
    "        \n",
    "        per_ent = Span(doc, start, end, label = \"PERSON\")\n",
    "        original_ents.append(per_ent)\n",
    "    doc.ents = original_ents\n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d92c7ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.paul_ner(doc)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp2 = spacy.blank(\"en\")\n",
    "nlp2.add_pipe(\"paul_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c70683b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Paul Newman, Paul Hollywood)\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp2(text)\n",
    "print (doc2.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "@Language.component(\"cinema_ner\")\n",
    "def cinema_ner(doc):\n",
    "    pattern = r\"Hollywood\" \n",
    "    original_ents = list (doc.ents) \n",
    "    mwt_ents = [] \n",
    "    for match in re.finditer(pattern, doc.text):\n",
    "        start, end = match.span()\n",
    "\n",
    "        span = doc.char_span(start,end)\n",
    "        if span is not None:\n",
    "            mwt_ents.append((span.start, span.end, span.text))\n",
    "\n",
    "    for ent in mwt_ents: \n",
    "        start, end, name =ent\n",
    "        \n",
    "        per_ent = Span(doc, start, end, label = \"CINEMA\")\n",
    "        original_ents.append(per_ent)\n",
    "    filtered = filter_spans(original_ents) #Clean up and deduplicate spans that overlap or conflict, keeping only the best ones.\n",
    "                                           #Hollywood might already be labeled by spaCy's built-in NER \n",
    "    doc.ents = filtered\n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2506d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cinema_ner(doc)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp3 = spacy.load(\"en_core_web_sm\")\n",
    "nlp3.add_pipe(\"cinema_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8208d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Newman PERSON\n",
      "American NORP\n",
      "Paul Hollywood PERSON\n",
      "British NORP\n",
      "Paul PERSON\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp3(text)\n",
    "for ent in doc3.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92486c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c619a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
