{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a6a047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bcc806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb4b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfde32",
   "metadata": {},
   "source": [
    "### Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d066b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445982933044434, 0.11197470128536224, 0.04342701658606529]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier (\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels = [\"education\", \"politics\", \"business\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3badaf8",
   "metadata": {},
   "source": [
    "### text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a751ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hamza\\.cache\\huggingface\\hub\\models--openai-community--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator = (\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7957d",
   "metadata": {},
   "source": [
    "### using models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c550a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hamza\\.cache\\huggingface\\hub\\models--HuggingFaceTB--SmolLM2-360M. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to take a well-rounded approach to your studies. You will learn the best ways to use the different resources available to you, such as textbooks, online materials, and even your classmates and teachers. You will also learn how to evaluate the quality of the information you find and use it to help you succeed in your classes. We will also cover how to write your papers and essays and how to do research and make arguments.\\n\\nStudying for the SAT takes a lot of time and effort, but there are many tools and techniques that can make the process easier and more enjoyable. By following our study strategy, you can increase your chances of doing well on the SAT and graduate with honors.'},\n",
       " {'generated_text': 'In this course, we will teach you how to make people really like you and become the person you want to be.\\n\\nYou will learn how to use your own personality to your advantage. How to build a great self-esteem. How to get what you want. How to get closer to people. How to become a better person. How to become the best version of yourself.\\n\\nYou will learn how to be happy in a world thatâ€™s changing too fast. You will understand how to make good friends and how to make bad friends. How to get things done. How to make decisions. How to be a leader.\\n\\nYou will learn how to deal with adversity and how to deal with problems. You will learn how to become a better person by making the right choices. You will learn how to be the person you want to be.\\n\\nYou will learn how to make friends. You will learn how to make decisions. You will learn how to make good decisions. You will learn how to make the best decisions. You will learn how to be a leader.\\n\\nYou will learn how to become the best version of yourself. You will learn how to make good friends. You will learn how to make good decisions. You will learn how to make the best decisions. You will learn how'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline (\"text-generation\", model =\"HuggingFaceTB/SmolLM2-360M\")\n",
    "generator (\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length = 30,\n",
    "    num_return_sequences = 2\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4bd738",
   "metadata": {},
   "source": [
    "### masking filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hamza\\.cache\\huggingface\\hub\\models--distilbert--distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1961977481842041,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052729159593582,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline (\"fill-mask\") \n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k = 2) #fill the missing word <mask>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b1679",
   "metadata": {},
   "source": [
    "### Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98dc3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.999278),\n",
       "  'word': 'Mohamed',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.99791926),\n",
       "  'word': 'VOIS',\n",
       "  'start': 33,\n",
       "  'end': 37},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9997874),\n",
       "  'word': 'Egypt',\n",
       "  'start': 41,\n",
       "  'end': 46}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline (\"ner\", grouped_entities = True,device = 0)\n",
    "ner(\"My name is Mohamed and I work at VOIS in Egypt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02b3ef",
   "metadata": {},
   "source": [
    "### question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5102d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.94860911665819, 'start': 33, 'end': 37, 'answer': 'VOIS'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer = pipeline(\"question-answering\")\n",
    "question_answer(\n",
    "    question = \"where do I work\", \n",
    "    context = \"My name is Mohamed and i work in VOIS\",\n",
    "    device = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87c2a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f75d9f",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e60be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:798: UserWarning: Not enough free disk space to download the file. The expected file size is: 1222.28 MB. The target location C:\\Users\\hamza\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\blobs only has 78.43 MB free disk space.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil, electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India, as well as other industrial countries, continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23990203",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fbb515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:798: UserWarning: Not enough free disk space to download the file. The expected file size is: 300.80 MB. The target location C:\\Users\\hamza\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-fr-en\\blobs only has 246.89 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:798: UserWarning: Not enough free disk space to download the file. The expected file size is: 300.80 MB. The target location C:\\Users\\hamza\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-fr-en\\blobs only has 246.91 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:798: UserWarning: Not enough free disk space to download the file. The expected file size is: 300.80 MB. The target location C:\\Users\\hamza\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-fr-en\\blobs only has 21.54 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:798: UserWarning: Not enough free disk space to download the file. The expected file size is: 300.80 MB. The target location C:\\Users\\hamza\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-fr-en\\blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model Helsinki-NLP/opus-mt-fr-en with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>, <class 'transformers.models.marian.modeling_marian.MarianMTModel'>, <class 'transformers.models.marian.modeling_tf_marian.TFMarianMTModel'>). See the original errors:\n\nwhile loading with AutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nwhile loading with TFAutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2813, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2869, in from_pretrained\n    raise OSError(\n    ...<4 lines>...\n    )\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2813, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2869, in from_pretrained\n    raise OSError(\n    ...<4 lines>...\n    )\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\nwhile loading with MarianMTModel, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nwhile loading with TFMarianMTModel, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2813, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2869, in from_pretrained\n    raise OSError(\n    ...<4 lines>...\n    )\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2813, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2869, in from_pretrained\n    raise OSError(\n    ...<4 lines>...\n    )\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m translator = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranslation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHelsinki-NLP/opus-mt-fr-en\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m translator(\u001b[33m\"\u001b[39m\u001b[33mCe cours est produit par Hugging Face.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1027\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n\u001b[32m   1039\u001b[39m \u001b[38;5;66;03m# Check which preprocessing classes the pipeline uses\u001b[39;00m\n\u001b[32m   1040\u001b[39m \u001b[38;5;66;03m# None values indicate optional classes that the pipeline can run without, we don't raise errors if loading fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py:333\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback.items():\n\u001b[32m    332\u001b[39m             error += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    334\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    335\u001b[39m         )\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    338\u001b[39m     framework = infer_framework(model.\u001b[34m__class__\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Could not load model Helsinki-NLP/opus-mt-fr-en with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>, <class 'transformers.models.marian.modeling_marian.MarianMTModel'>, <class 'transformers.models.marian.modeling_tf_marian.TFMarianMTModel'>). See the original errors:\n\nwhile loading with AutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nwhile loading with TFAutoModelForSeq2SeqLM, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2813, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2869, in from_pretrained\n    raise OSError(\n    ...<4 lines>...\n    )\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2813, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2869, in from_pretrained\n    raise OSError(\n    ...<4 lines>...\n    )\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\nwhile loading with MarianMTModel, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1037, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 277, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4900, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1160, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<5 lines>...\n    ) from e\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nwhile loading with TFMarianMTModel, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2813, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2869, in from_pretrained\n    raise OSError(\n    ...<4 lines>...\n    )\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2813, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 322, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 567, in cached_files\n    raise e\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 479, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1007, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1168, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1720, in _download_to_tmp_and_move\n    xet_get(\n    ~~~~~~~^\n        incomplete_path=incomplete_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        displayed_filename=filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 626, in xet_get\n    download_files(\n    ~~~~~~~~~~~~~~^\n        xet_download_info,\n        ^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n        progress_updater=[progress_updater],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\nRuntimeError: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\hamza\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2869, in from_pretrained\n    raise OSError(\n    ...<4 lines>...\n    )\nOSError: Can't load the model for 'Helsinki-NLP/opus-mt-fr-en'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Helsinki-NLP/opus-mt-fr-en' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5 or model.ckpt\n\n\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a404a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
